{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73a804067d94aabb99b8b43ae07c42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## NOTE: I used many ideas from this article and python notebook:\n",
    "## https://towardsdatascience.com/machine-learning-with-pyspark-and-amazon-emr-3149dbc847ae\n",
    "## https://github.com/maleckicoa/Sparkify-Project/blob/master/Sparkify_Big.ipynb\n",
    "\n",
    "sc.install_pypi_package(\"pandas==0.25.1\") \n",
    "sc.install_pypi_package(\"scikit-learn\")\n",
    "sc.install_pypi_package(\"quinn\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler, Normalizer, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1e31c814f4434296cdc56eb94138de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"CS643_Project\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd6f5c5ab80454883d991c49be9cbc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Load Training Dataset\n",
    "train_df = spark.read.format('csv').options(header='true', inferSchema='true', sep=';').load('s3a://cs643johndaudelin/TrainingDataset.csv')\n",
    "validation_df = spark.read.format('csv').options(header='true', inferSchema='true', sep=';').load('s3a://cs643johndaudelin/ValidationDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905c6e1ec69b452fa16256135249c39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def remove_quotations(s):\n",
    "    return s.replace('\"', '')\n",
    "\n",
    "train_df = quinn.with_columns_renamed(remove_quotations)(train_df)\n",
    "train_df.withColumnRenamed('quality', 'label')\n",
    "\n",
    "validation_df = quinn.with_columns_renamed(remove_quotations)(validation_df)\n",
    "validation_df.withColumnRenamed('quality', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d133973d0f2493cadbd481460b11c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"fixed acidity\",\n",
    "               \"volatile acidity\",\n",
    "               \"citric acid\",\n",
    "               \"residual sugar\",\n",
    "               \"chlorides\",\n",
    "               \"free sulfur dioxide\",\n",
    "               \"total sulfur dioxide\",\n",
    "               \"density\",\n",
    "               \"pH\",\n",
    "               \"sulphates\",\n",
    "               \"alcohol\"],\n",
    "                outputCol=\"inputFeatures\")\n",
    "\n",
    "scaler = Normalizer(inputCol=\"inputFeatures\", outputCol=\"features\")\n",
    "\n",
    "lr=LogisticRegression()\n",
    "rf= RandomForestClassifier()\n",
    "\n",
    "pipeline1=Pipeline(stages=[assembler, scaler, lr])\n",
    "pipeline2 = Pipeline(stages=[assembler, scaler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4606a7e2fdb4a38b535253f90ba802c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.562631807944308"
     ]
    }
   ],
   "source": [
    "paramgrid =ParamGridBuilder().build()\n",
    "\n",
    "evaluator=MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "\n",
    "crossval= CrossValidator(estimator=pipeline1,  \n",
    "                         estimatorParamMaps=paramgrid,\n",
    "                         evaluator=evaluator, \n",
    "                         numFolds=3\n",
    "                        )\n",
    "\n",
    "cvModel1=crossval.fit(train_df) \n",
    "evaluator.evaluate(cvModel1.transform(validation_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6faf378da3ca434ba6b7296958c0d722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47683839637797576"
     ]
    }
   ],
   "source": [
    "crossval= CrossValidator(estimator=pipeline2,  \n",
    "                         estimatorParamMaps=paramgrid,\n",
    "                         evaluator=evaluator, \n",
    "                         numFolds=3\n",
    "                        )\n",
    "\n",
    "cvModel2=crossval.fit(train_df) \n",
    "evaluator.evaluate(cvModel2.transform(validation_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alternative way of making model: See https://towardsdatascience.com/your-first-apache-spark-ml-model-d2bb82b599dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.install_pypi_package(\"pyspark2pmml\")\n",
    "\n",
    "# from pyspark2pmml import PMMLBuilder\n",
    "# pmmlBuilder = PMMLBuilder(sc, train_df, model).putOption(classifier, \"compact\", True)\n",
    "# pmmlBuilder.buildFile(\"DecisionTreeModel.pmml\")\n",
    "\n",
    "## NEED TO INSTALL https://github.com/jpmml/jpmml-sparkml on EC2's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jpmml_sparkml import toPMMLBytes\n",
    "pmmlBytes = toPMMLBytes(sc, df, pipelineModel)\n",
    "print(pmmlBytes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
